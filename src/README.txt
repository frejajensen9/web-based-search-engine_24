Project Title: COMP4321 Group 24 (Phase 1)

1. Introduction

This project implements a web-based spider (crawler) integrated with an indexer. The spider uses a breadth-first strategy (BFS) to crawl web pages starting from a given URL, extracts hyperlinks and page content, and builds several indexes using JDBM’s HTree file structures. In addition, the indexer processes page content by removing stop words, stemming the remaining words using Porter’s algorithm, and building two types of inverted indexes:
 • A simple inverted index mapping each stemmed word (from the page body) to the list of page IDs.
 • A positions inverted index that maps each stemmed word to a mapping (page ID → list of token positions) to support phrase searches.
Additionally, the title of each page is stored and indexed to allow boosting during retrieval.

2. Build Instructions

Requirements:
  - Java Development Kit (JDK) 17 or later.
  - JDBM library (for key-value storage with HTrees).
  - HTMLParser library (for parsing HTML and extracting links/content).

Compilation:
  1. Place all the source files (Spider.java, Porter.java, and stopwords.txt) in the appropriate directory structure. (The stopwords.txt file should be accessible as specified in the code, e.g., under src/stopwords.txt.)
  2. Include the JDBM and HTMLParser JAR files in your classpath.
  3. Compile the Java files. For example, from the command line:
     
     javac -cp ".;jdbm.jar;htmlparser.jar" Spider.java Porter.java

3. Execution Instructions

To run the spider and indexer:
  1. Execute the main class. For example:
     
     java -cp ".;jdbm.jar;htmlparser.jar" Spider

  2. The spider will start crawling from the given URL (as specified in the main method) and will index up to 30 pages.
  3. After crawling and indexing, a file named `spider_result.txt` will be generated, containing the following for each page:
     - Page title
     - URL
     - Last modification date and page size
     - Up to 10 keywords (stemmed words with frequency)
     - List of child links (extracted hyperlinks)
  4. The JDBM database file (e.g., "spider_db") is created in the working directory. This file is used for storage and can be reused or deleted as needed.

4. File Structure

 • Spider.java            – Main class implementing the web crawler and indexer, including phrase search support.
 • Porter.java            – Implementation of the Porter stemmer for word stemming.
 • stopwords.txt          – List of stop words used to filter common words from being indexed.
 • spider_result.txt      – Output file generated by the test program, summarizing indexed page details.
 • README.txt             – This document.
 • Database Schema.txt    – Detailed description of the JDBM database design and file structures.

5. Additional Notes

 • The code uses JDBM’s HTrees to maintain five different indexes:
     - URL-to-pageID mapping (pageIndex)
     - Body text inverted index (invertedIndexBody)
     - Title index (invertedIndexTitle)
     - Parent-to-child link mapping (parentChildLinks)
 • error messages will be output to the console if there are any issues.
