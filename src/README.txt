Project Title: COMP4321 Group 24 (Phase 1)

1.Introduction

This project implements a web-based spider (crawler) integrated with an indexer. The spider uses a breadth-first strategy (BFS) to crawl web pages starting from a given URL, extract hyperlinks and page content, and build several indexes using JDBM’s HTree file structures. In addition, the indexer processes page content by removing stop words and stemming the remaining words using Porter’s algorithm, and builds the following indexes:

A simple inverted index mapping each stemmed word (from the page body) to the list of page IDs.
A title index that stores the title of each page, keyed by page ID, allowing for title-based boosting during retrieval.
Additionally, the crawler records the link relationships between pages by storing parent-to-child mappings.

2.Build Instructions

Requirements:
Java Development Kit (JDK) 17 or later.
JDBM library (for key-value storage with HTrees).
HTMLParser library (for parsing HTML and extracting links/content).

Compilation:
Place all the source files (Spider.java, Porter.java, and stopwords.txt) in the appropriate directory structure. (The stopwords.txt file should be accessible as specified in the code, e.g., under src/stopwords.txt.)
Include the JDBM and HTMLParser JAR files in your classpath.
Compile the Java files. For example, from the command line:
javac -cp ".;jdbm.jar;htmlparser.jar" Spider.java Porter.java

Execution Instructions
To run the spider and indexer:
Execute the main class. For example:
java -cp ".;jdbm.jar;htmlparser.jar" Spider

The spider will start crawling from the given URL (as specified in the main method) and will index up to 30 pages.

After crawling and indexing, a file named spider_result.txt will be generated, containing the following details for each page:

Page title
URL
Last modification date and page size
Up to 10 keywords (stemmed words with frequency)
List of child links (extracted hyperlinks)
The JDBM database file (e.g., "spider_db") is created in the working directory. This file is used for storage and can be reused or deleted as needed.

File Structure

• Spider.java – Main class implementing the web crawler and indexer.
• Porter.java – Implementation of the Porter stemmer for word stemming.
• stopwords.txt – List of stop words used to filter common words from being indexed.
• spider_result.txt – Output file generated by the test program, summarizing indexed page details.

Database Files Output:

When the program runs, the JDBM RecordManager creates a database file named "spider_db.db" and a log file "spider_db.lg" in the working directory.
spider_db.db: This file contains the actual stored data (HTree structures for pageIndex, invertedIndexBody, invertedIndexTitle, and parentChildLinks). It represents the persistent storage for the indexes.
spider_db.lg: This log file records transaction logs and changes made to the database. It is used by the JDBM library to ensure data integrity and to support recovery in case of system failures.
Both files are automatically generated and updated by the JDBM library during indexing and commit operations.

Additional Notes:

The code uses JDBM’s HTrees to maintain four different indexes:

1. URL-to-pageID mapping (pageIndex): Maps each URL to a unique page ID.
2. Body text inverted index (invertedIndexBody): Maps each stemmed word from the page body to a list of page IDs where the word appears.
3. Title index (invertedIndexTitle): Stores the title of each page, keyed by page ID.
4. Parent-to-child link mapping (parentChildLinks): Records the link relationships between pages using composite keys (formatted as "pageID->childURL").